{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "EYz4W9vbzLw_"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install -q langchain_core langchain-openai requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage, ToolMessage\n",
        "import requests"
      ],
      "metadata": {
        "id": "_iWnFf7izw2q"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tool create\n",
        "@tool\n",
        "def multiply_two_numbers(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two numbers and return its value from third number \"\"\"\n",
        "    return a * b"
      ],
      "metadata": {
        "id": "lpIVeYcwz1FF"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(multiply_two_numbers.invoke({\"a\": 5, \"b\": -6}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILuQ3Okm0Cid",
        "outputId": "bc1048bd-e150-46bd-d9c6-60731ade3b1d"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply_two_numbers.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GV1F2uvf1IKq",
        "outputId": "b9e12e40-77c3-459e-dd90-c4a56687b6b2"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'multiply_two_numbers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply_two_numbers.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy9UXBv11LE5",
        "outputId": "c8bcbdab-9c5c-4218-db63-e54c4ccb2157"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': {'title': 'A', 'type': 'integer'},\n",
              " 'b': {'title': 'B', 'type': 'integer'}}"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multiply_two_numbers.args_schema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "jdEfYsut1O2p",
        "outputId": "d706044a-d9c4-478b-e7f5-103b2004e381"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.utils.pydantic.multiply_two_numbers"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.utils.pydantic.multiply_two_numbers</b><br/>def __init__(self, /, **data: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/utils/pydantic.py</a>Multiply two numbers and return its value from third number </pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, None);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool Binding"
      ],
      "metadata": {
        "id": "RLp2G5jW17CU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its is step where we registers **Custom** or **Structured** tools with LLM so that\n",
        "a. LLM knows what all tools are available for its `functioning`.\n",
        "b. LLM knows what each tools `does`.\n",
        "c. LLM knows what `input format` to use for each tools. This is done via reading the schema of the tools."
      ],
      "metadata": {
        "id": "VzL6wpxu27gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\",temperature=0, api_key=\"\")"
      ],
      "metadata": {
        "id": "LKyJ_FhR1Tvp"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools = llm.bind_tools([multiply_two_numbers])"
      ],
      "metadata": {
        "id": "xVILVtVP2aaR"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool Calling"
      ],
      "metadata": {
        "id": "8e4CZKmo49_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is the process whre the LLM decides, during a conversation or task, that it needs to use a specific tool(function)\n",
        "and generates a structured output(Schema) which has following: </br>\n",
        "\n",
        "a. the `name of the tool`\n",
        "b. and the `arguments` to call it with\n",
        "\n",
        "The LLM does not run the tool, it just suggest the tool and the input argument. The actual execution is handled by **LanChain**."
      ],
      "metadata": {
        "id": "dfCnBjwg5C4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message_list = []\n",
        "message1 = HumanMessage(content=\"Hi How are you\")\n",
        "message_list.append(message1)\n",
        "message_list.append(llm_with_tools.invoke ([message1]))"
      ],
      "metadata": {
        "id": "tvR-zdwi5CN6"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMEs-QeO52dP",
        "outputId": "47ce8cca-fe01-4ca3-bd23-ea4d612f2f09"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi How are you', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 58, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CgW4m1AauivaIxZ0tVyfrkVn1nU5V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--90003d6f-4e50-4222-b3b5-efaf4e065598-0', usage_metadata={'input_tokens': 58, 'output_tokens': 37, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message2 = HumanMessage('Multiply two numbers where number 1 has value 9 and number 2 has value -18')\n",
        "message_list.append(message2)\n",
        "message_list"
      ],
      "metadata": {
        "id": "5Fe4UXKMDh6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94aa513c-28bb-4aee-c400-c7fe55c36d58"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi How are you', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 58, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CgW4m1AauivaIxZ0tVyfrkVn1nU5V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--90003d6f-4e50-4222-b3b5-efaf4e065598-0', usage_metadata={'input_tokens': 58, 'output_tokens': 37, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " HumanMessage(content='Multiply two numbers where number 1 has value 9 and number 2 has value -18', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = llm_with_tools.invoke(message_list)\n",
        "message_list.append(result)\n",
        "message_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYvLEx0RWmMs",
        "outputId": "139a44e0-5da0-42cc-d768-1a8c0eb1fa08"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi How are you', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 58, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CgW4m1AauivaIxZ0tVyfrkVn1nU5V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--90003d6f-4e50-4222-b3b5-efaf4e065598-0', usage_metadata={'input_tokens': 58, 'output_tokens': 37, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " HumanMessage(content='Multiply two numbers where number 1 has value 9 and number 2 has value -18', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 121, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CgW4nJngu359ZORnY6E2VFsNYBKo7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--a39313c6-e59c-4d0f-89a2-8710d6762987-0', tool_calls=[{'name': 'multiply_two_numbers', 'args': {'a': 9, 'b': -18}, 'id': 'call_khwhUGcguRXvI7lvsDOunz6S', 'type': 'tool_call'}], usage_metadata={'input_tokens': 121, 'output_tokens': 19, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When message1 is 'Hi How are you',\n",
        "* then AI message content is *AIMessage(content=\"I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\",*\n",
        "\n",
        "When message2 is ' Multiplication of two numbers'\n",
        "* then AI message content is spaces  AIMessage(content='',\n",
        "* and it has tool_calls which means it does not uses its own context but fetches the tools it was binded with\n",
        "  *tool_calls=[{'name': 'multiply_two_numbers', 'args': {'a': 9, 'b': -18, 'c': 0}, 'id': 'call_w95szkN0ZTGPYQX6tfXh4jXy', 'type': 'tool_call'}]*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vfyDQIij6Tih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tool Execution"
      ],
      "metadata": {
        "id": "jGrMW_a-BDl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is the step where the actual Tool is run using the input arguments that LLM suggested during tool calling.\n",
        "\n",
        "eg.\n",
        "LLM says 'Hey, call the multiply tool with input parameters a =10, b= 20  </br>\n",
        "Tool Execution is when LangChain actually run the mutiply operation (a =10, b= 20 ) and get the result = 200"
      ],
      "metadata": {
        "id": "32rJlVAeBhPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args= result.tool_calls[0]\n",
        "args"
      ],
      "metadata": {
        "id": "CCBv0T-eBcBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175f4a98-cfcf-44dc-8284-74f583410b6f"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'multiply_two_numbers',\n",
              " 'args': {'a': 9, 'b': -18},\n",
              " 'id': 'call_khwhUGcguRXvI7lvsDOunz6S',\n",
              " 'type': 'tool_call'}"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_result = multiply_two_numbers.invoke(args)\n",
        "tool_result"
      ],
      "metadata": {
        "id": "L0OBMWcECRyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a59990-b732-4008-f670-f7cbfcf8ad49"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToolMessage(content='-162', name='multiply_two_numbers', tool_call_id='call_khwhUGcguRXvI7lvsDOunz6S')"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_list.append(tool_result)\n",
        "message_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fi5eMfyMW08",
        "outputId": "ea76391d-2ef4-47ba-f302-b5dd48ed725c"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='Hi How are you', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content=\"I'm just a computer program, so I don't have feelings, but I'm here to help you with any questions or tasks you have. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 58, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CgW4m1AauivaIxZ0tVyfrkVn1nU5V', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--90003d6f-4e50-4222-b3b5-efaf4e065598-0', usage_metadata={'input_tokens': 58, 'output_tokens': 37, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " HumanMessage(content='Multiply two numbers where number 1 has value 9 and number 2 has value -18', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 121, 'total_tokens': 140, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CgW4nJngu359ZORnY6E2VFsNYBKo7', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--a39313c6-e59c-4d0f-89a2-8710d6762987-0', tool_calls=[{'name': 'multiply_two_numbers', 'args': {'a': 9, 'b': -18}, 'id': 'call_khwhUGcguRXvI7lvsDOunz6S', 'type': 'tool_call'}], usage_metadata={'input_tokens': 121, 'output_tokens': 19, 'total_tokens': 140, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " ToolMessage(content='-162', name='multiply_two_numbers', tool_call_id='call_khwhUGcguRXvI7lvsDOunz6S')]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_with_tools.invoke (message_list).content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "g1s5QxVgPGAn",
        "outputId": "7b3e61b9-986d-4c4f-af96-7006223309e4"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The result of multiplying 9 and -18 is -162.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    }
  ]
}